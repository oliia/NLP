{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project-NLP1-Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "19mbXkg6IPQeGJmneHqohJuepFB2BQx96",
      "authorship_tag": "ABX9TyODms1f0d1D2UJVnOIneAW9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oliia/NLP/blob/master/Project_NLP1_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE_nIY9Eak1_",
        "colab_type": "text"
      },
      "source": [
        "# 1 Pre Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXGQsCIMYER8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "3e00e38f-e481-4872-e4e9-3c0bc418caac"
      },
      "source": [
        "import pandas as pd\n",
        "sms = pd.read_table('/content/SMSSpamCollection', header=None)\n",
        "\n",
        "print(sms)\n",
        "\n",
        "print(sms.head())\n",
        "\n",
        "sms.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         0                                                  1\n",
            "0      ham  Go until jurong point, crazy.. Available only ...\n",
            "1      ham                      Ok lar... Joking wif u oni...\n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      ham  U dun say so early hor... U c already then say...\n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
            "...    ...                                                ...\n",
            "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
            "5568   ham               Will ü b going to esplanade fr home?\n",
            "5569   ham  Pity, * was in mood for that. So...any other s...\n",
            "5570   ham  The guy did some bitching but I acted like i'd...\n",
            "5571   ham                         Rofl. Its true to its name\n",
            "\n",
            "[5572 rows x 2 columns]\n",
            "      0                                                  1\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5572</td>\n",
              "      <td>5572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2</td>\n",
              "      <td>5169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>ham</td>\n",
              "      <td>Sorry, I'll call later</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>4825</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0                       1\n",
              "count   5572                    5572\n",
              "unique     2                    5169\n",
              "top      ham  Sorry, I'll call later\n",
              "freq    4825                      30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh3-Mstea3uq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6d74abfa-a679-4129-b19b-4ee1c3dd0c5c"
      },
      "source": [
        "## Data Info \n",
        "\n",
        "# Vecteur de valeurs cibles : \n",
        "y = sms[0]\n",
        "y.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ham     4825\n",
              "spam     747\n",
              "Name: 0, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPl4RZsncLm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "acbc1d0c-6eca-45cd-808e-ae8367818f62"
      },
      "source": [
        "  # qu'il faut encoder en numérique :\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "\n",
        "y_enc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4hEagF0coel",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "4b61300e-b7af-4cce-d52b-d8d11dcf0fc0"
      },
      "source": [
        "# Création de la matrice des exemples\n",
        "raw_text = sms[1]\n",
        "\n",
        "print(raw_text)\n",
        "\n",
        "print(pd.isnull(sms))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       Go until jurong point, crazy.. Available only ...\n",
            "1                           Ok lar... Joking wif u oni...\n",
            "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3       U dun say so early hor... U c already then say...\n",
            "4       Nah I don't think he goes to usf, he lives aro...\n",
            "                              ...                        \n",
            "5567    This is the 2nd time we have tried 2 contact u...\n",
            "5568                 Will ü b going to esplanade fr home?\n",
            "5569    Pity, * was in mood for that. So...any other s...\n",
            "5570    The guy did some bitching but I acted like i'd...\n",
            "5571                           Rofl. Its true to its name\n",
            "Name: 1, Length: 5572, dtype: object\n",
            "          0      1\n",
            "0     False  False\n",
            "1     False  False\n",
            "2     False  False\n",
            "3     False  False\n",
            "4     False  False\n",
            "...     ...    ...\n",
            "5567  False  False\n",
            "5568  False  False\n",
            "5569  False  False\n",
            "5570  False  False\n",
            "5571  False  False\n",
            "\n",
            "[5572 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqXPZVHhfGld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "5be76f4d-81c0-487b-b621-5226eb3d1b70"
      },
      "source": [
        "# Basic Visualization\n",
        "\n",
        "import matplotlib as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sms.columns=['label', 'msg']\n",
        "sms.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>msg</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                                msg  length\n",
              "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
              "1   ham                      Ok lar... Joking wif u oni...      29\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
              "3   ham  U dun say so early hor... U c already then say...      49\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S0kcjQJfZYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "134846bc-b618-46ee-c0b9-b522f1158c0f"
      },
      "source": [
        "    # ajout de mesures \n",
        "sms[\"length\"] = sms[\"msg\"].apply(len)\n",
        "sms.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lbl</th>\n",
              "      <th>msg</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    lbl                                                msg  length\n",
              "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
              "1   ham                      Ok lar... Joking wif u oni...      29\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
              "3   ham  U dun say so early hor... U c already then say...      49\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fegDoCMyfnHV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "79a73b24-423e-4a1f-c187-11dde17d2588"
      },
      "source": [
        "sns.distplot(sms[\"length\"], kde = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f591caba588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVX5_Ld1hw8p",
        "colab_type": "text"
      },
      "source": [
        "## 2 Pre-Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hGmvv17hozh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "22661487-0ca0-4003-f361-ea551c780883"
      },
      "source": [
        "# Step 1: Contraction Mapping / Expanding Contractions\n",
        "!pip install contractions\n",
        "import contractions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/00/92/a05b76a692ac08d470ae5c23873cf1c9a041532f1ee065e74b374f218306/contractions-0.0.25-py2.py3-none-any.whl\n",
            "Collecting textsearch\n",
            "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
            "Collecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 3.9MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 18.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81702 sha256=07c927481d79d327b4ef57433bc635358b1c3e40e72e514a0d5b54394ac26ab9\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: Unidecode, pyahocorasick, textsearch, contractions\n",
            "Successfully installed Unidecode-1.1.1 contractions-0.0.25 pyahocorasick-1.4.0 textsearch-0.0.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMb-XwGfiF2K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "62980e9c-59ec-452d-e0cd-b3e70e707b20"
      },
      "source": [
        "    # creation d'une nouvelle colonne sans contractions\n",
        "sms['no_contract'] = sms['msg'].apply(lambda x: [contractions.fix(word) for word in x.split()])\n",
        "print(sms.head())\n",
        "    # we would want the expanded contractions to be tokenized separately, therefore we convert the lists under the \"no_contract\" column back into strings\n",
        "sms[\"msg_str\"] = [' '.join(map(str, l)) for l in sms['no_contract']]\n",
        "sms.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  label  ...                                          tokenized\n",
            "0   ham  ...  [Go, until, jurong, point, ,, crazy.., Availab...\n",
            "1   ham  ...         [Ok, lar, ..., Joking, wif, you, oni, ...]\n",
            "2  spam  ...  [Free, entry, in, 2, a, wkly, comp, to, win, F...\n",
            "3   ham  ...  [you, dun, say, so, early, hor, ..., you, c, a...\n",
            "4   ham  ...  [Nah, I, do, not, think, he, goes, to, usf, ,,...\n",
            "\n",
            "[5 rows x 6 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>msg</th>\n",
              "      <th>length</th>\n",
              "      <th>no_contract</th>\n",
              "      <th>msg_str</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "      <td>[Go, until, jurong, point,, crazy.., Available...</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>[Go, until, jurong, point, ,, crazy.., Availab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "      <td>[Ok, lar..., Joking, wif, you, oni...]</td>\n",
              "      <td>Ok lar... Joking wif you oni...</td>\n",
              "      <td>[Ok, lar, ..., Joking, wif, you, oni, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "      <td>[you, dun, say, so, early, hor..., you, c, alr...</td>\n",
              "      <td>you dun say so early hor... you c already then...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "      <td>[Nah, I, do not, think, he, goes, to, usf,, he...</td>\n",
              "      <td>Nah I do not think he goes to usf, he lives ar...</td>\n",
              "      <td>[Nah, I, do, not, think, he, goes, to, usf, ,,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                          tokenized\n",
              "0   ham  ...  [Go, until, jurong, point, ,, crazy.., Availab...\n",
              "1   ham  ...         [Ok, lar, ..., Joking, wif, you, oni, ...]\n",
              "2  spam  ...  [Free, entry, in, 2, a, wkly, comp, to, win, F...\n",
              "3   ham  ...  [you, dun, say, so, early, hor, ..., you, c, a...\n",
              "4   ham  ...  [Nah, I, do, not, think, he, goes, to, usf, ,,...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXK66me2lem1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "5f37bd91-0058-4f58-8797-3d2269ddca92"
      },
      "source": [
        "    # tokenization\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "sms['tokenized'] = sms['msg_str'].apply(word_tokenize)\n",
        "sms.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>msg</th>\n",
              "      <th>length</th>\n",
              "      <th>no_contract</th>\n",
              "      <th>msg_str</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "      <td>[Go, until, jurong, point,, crazy.., Available...</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>[Go, until, jurong, point, ,, crazy.., Availab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "      <td>[Ok, lar..., Joking, wif, you, oni...]</td>\n",
              "      <td>Ok lar... Joking wif you oni...</td>\n",
              "      <td>[Ok, lar, ..., Joking, wif, you, oni, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "      <td>[you, dun, say, so, early, hor..., you, c, alr...</td>\n",
              "      <td>you dun say so early hor... you c already then...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "      <td>[Nah, I, do not, think, he, goes, to, usf,, he...</td>\n",
              "      <td>Nah I do not think he goes to usf, he lives ar...</td>\n",
              "      <td>[Nah, I, do, not, think, he, goes, to, usf, ,,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                          tokenized\n",
              "0   ham  ...  [Go, until, jurong, point, ,, crazy.., Availab...\n",
              "1   ham  ...         [Ok, lar, ..., Joking, wif, you, oni, ...]\n",
              "2  spam  ...  [Free, entry, in, 2, a, wkly, comp, to, win, F...\n",
              "3   ham  ...  [you, dun, say, so, early, hor, ..., you, c, a...\n",
              "4   ham  ...  [Nah, I, do, not, think, he, goes, to, usf, ,,...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLZpi7i1vV85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "5cc8f88c-dbe3-408e-b983-aad93a3060d3"
      },
      "source": [
        "    # Step 3: Noise Cleaning - spacing, special characters, lowercasing\n",
        "sms.sample(frac=0.05)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>msg</th>\n",
              "      <th>length</th>\n",
              "      <th>no_contract</th>\n",
              "      <th>msg_str</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2825</th>\n",
              "      <td>ham</td>\n",
              "      <td>No need to buy lunch for me.. I eat maggi mee..</td>\n",
              "      <td>47</td>\n",
              "      <td>[No, need, to, buy, lunch, for, me.., I, eat, ...</td>\n",
              "      <td>No need to buy lunch for me.. I eat maggi mee..</td>\n",
              "      <td>[No, need, to, buy, lunch, for, me.., I, eat, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>785</th>\n",
              "      <td>ham</td>\n",
              "      <td>Dont think so. It turns off like randomlly wit...</td>\n",
              "      <td>65</td>\n",
              "      <td>[do not, think, so., It, turns, off, like, ran...</td>\n",
              "      <td>do not think so. It turns off like randomlly w...</td>\n",
              "      <td>[do, not, think, so, ., It, turns, off, like, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1509</th>\n",
              "      <td>ham</td>\n",
              "      <td>Sounds like something that someone testing me ...</td>\n",
              "      <td>56</td>\n",
              "      <td>[Sounds, like, something, that, someone, testi...</td>\n",
              "      <td>Sounds like something that someone testing me ...</td>\n",
              "      <td>[Sounds, like, something, that, someone, testi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2651</th>\n",
              "      <td>ham</td>\n",
              "      <td>Do you like shaking your booty on the dance fl...</td>\n",
              "      <td>50</td>\n",
              "      <td>[Do, you, like, shaking, your, booty, on, the,...</td>\n",
              "      <td>Do you like shaking your booty on the dance fl...</td>\n",
              "      <td>[Do, you, like, shaking, your, booty, on, the,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1598</th>\n",
              "      <td>spam</td>\n",
              "      <td>URGENT! Your Mobile number has been awarded wi...</td>\n",
              "      <td>143</td>\n",
              "      <td>[URGENT!, Your, Mobile, number, has, been, awa...</td>\n",
              "      <td>URGENT! Your Mobile number has been awarded wi...</td>\n",
              "      <td>[URGENT, !, Your, Mobile, number, has, been, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>ham</td>\n",
              "      <td>Yup i'm still having coffee wif my frens... My...</td>\n",
              "      <td>82</td>\n",
              "      <td>[Yup, I am, still, having, coffee, wif, my, fr...</td>\n",
              "      <td>Yup I am still having coffee wif my frens... M...</td>\n",
              "      <td>[Yup, I, am, still, having, coffee, wif, my, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4112</th>\n",
              "      <td>spam</td>\n",
              "      <td>URGENT! Your Mobile number has been awarded a ...</td>\n",
              "      <td>141</td>\n",
              "      <td>[URGENT!, Your, Mobile, number, has, been, awa...</td>\n",
              "      <td>URGENT! Your Mobile number has been awarded a ...</td>\n",
              "      <td>[URGENT, !, Your, Mobile, number, has, been, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1220</th>\n",
              "      <td>ham</td>\n",
              "      <td>True. It is passable. And if you get a high sc...</td>\n",
              "      <td>119</td>\n",
              "      <td>[True., It, is, passable., And, if, you, get, ...</td>\n",
              "      <td>True. It is passable. And if you get a high sc...</td>\n",
              "      <td>[True, ., It, is, passable, ., And, if, you, g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>820</th>\n",
              "      <td>ham</td>\n",
              "      <td>BOO BABE! U ENJOYIN YOURJOB? U SEEMED 2 B GETT...</td>\n",
              "      <td>124</td>\n",
              "      <td>[BOO, BABE!, you, ENJOYIN, YOURJOB?, you, SEEM...</td>\n",
              "      <td>BOO BABE! you ENJOYIN YOURJOB? you SEEMED 2 B ...</td>\n",
              "      <td>[BOO, BABE, !, you, ENJOYIN, YOURJOB, ?, you, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5193</th>\n",
              "      <td>ham</td>\n",
              "      <td>It's wylie, you in tampa or sarasota?</td>\n",
              "      <td>37</td>\n",
              "      <td>[it is, wylie,, you, in, tampa, or, sarasota?]</td>\n",
              "      <td>it is wylie, you in tampa or sarasota?</td>\n",
              "      <td>[it, is, wylie, ,, you, in, tampa, or, sarasot...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>279 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label  ...                                          tokenized\n",
              "2825   ham  ...  [No, need, to, buy, lunch, for, me.., I, eat, ...\n",
              "785    ham  ...  [do, not, think, so, ., It, turns, off, like, ...\n",
              "1509   ham  ...  [Sounds, like, something, that, someone, testi...\n",
              "2651   ham  ...  [Do, you, like, shaking, your, booty, on, the,...\n",
              "1598  spam  ...  [URGENT, !, Your, Mobile, number, has, been, a...\n",
              "...    ...  ...                                                ...\n",
              "3262   ham  ...  [Yup, I, am, still, having, coffee, wif, my, f...\n",
              "4112  spam  ...  [URGENT, !, Your, Mobile, number, has, been, a...\n",
              "1220   ham  ...  [True, ., It, is, passable, ., And, if, you, g...\n",
              "820    ham  ...  [BOO, BABE, !, you, ENJOYIN, YOURJOB, ?, you, ...\n",
              "5193   ham  ...  [it, is, wylie, ,, you, in, tampa, or, sarasot...\n",
              "\n",
              "[279 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyTgMWevvkIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "50129177-f95d-4bd3-e80b-6af30a2780e2"
      },
      "source": [
        "sms['lower'] = sms['tokenized'].apply(lambda x: [word.lower() for word in x])\n",
        "sms.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>msg</th>\n",
              "      <th>length</th>\n",
              "      <th>no_contract</th>\n",
              "      <th>msg_str</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>lower</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "      <td>[Go, until, jurong, point,, crazy.., Available...</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>[Go, until, jurong, point, ,, crazy.., Availab...</td>\n",
              "      <td>[go, until, jurong, point, ,, crazy.., availab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "      <td>[Ok, lar..., Joking, wif, you, oni...]</td>\n",
              "      <td>Ok lar... Joking wif you oni...</td>\n",
              "      <td>[Ok, lar, ..., Joking, wif, you, oni, ...]</td>\n",
              "      <td>[ok, lar, ..., joking, wif, you, oni, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "      <td>[you, dun, say, so, early, hor..., you, c, alr...</td>\n",
              "      <td>you dun say so early hor... you c already then...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "      <td>[Nah, I, do not, think, he, goes, to, usf,, he...</td>\n",
              "      <td>Nah I do not think he goes to usf, he lives ar...</td>\n",
              "      <td>[Nah, I, do, not, think, he, goes, to, usf, ,,...</td>\n",
              "      <td>[nah, i, do, not, think, he, goes, to, usf, ,,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                              lower\n",
              "0   ham  ...  [go, until, jurong, point, ,, crazy.., availab...\n",
              "1   ham  ...         [ok, lar, ..., joking, wif, you, oni, ...]\n",
              "2  spam  ...  [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
              "3   ham  ...  [you, dun, say, so, early, hor, ..., you, c, a...\n",
              "4   ham  ...  [nah, i, do, not, think, he, goes, to, usf, ,,...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3dQBzWgvkz5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "14b68cfa-eefe-4c5c-eb66-eabdfdc269a4"
      },
      "source": [
        "    # Ponctuation\n",
        "import string\n",
        "punc = string.punctuation\n",
        "sms['no_punc'] = sms['lower'].apply(lambda x: [word for word in x if word not in punc])\n",
        "sms.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>msg</th>\n",
              "      <th>length</th>\n",
              "      <th>no_contract</th>\n",
              "      <th>msg_str</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>lower</th>\n",
              "      <th>no_punc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "      <td>[Go, until, jurong, point,, crazy.., Available...</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>[Go, until, jurong, point, ,, crazy.., Availab...</td>\n",
              "      <td>[go, until, jurong, point, ,, crazy.., availab...</td>\n",
              "      <td>[go, until, jurong, point, crazy.., available,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "      <td>[Ok, lar..., Joking, wif, you, oni...]</td>\n",
              "      <td>Ok lar... Joking wif you oni...</td>\n",
              "      <td>[Ok, lar, ..., Joking, wif, you, oni, ...]</td>\n",
              "      <td>[ok, lar, ..., joking, wif, you, oni, ...]</td>\n",
              "      <td>[ok, lar, ..., joking, wif, you, oni, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "      <td>[you, dun, say, so, early, hor..., you, c, alr...</td>\n",
              "      <td>you dun say so early hor... you c already then...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "      <td>[Nah, I, do not, think, he, goes, to, usf,, he...</td>\n",
              "      <td>Nah I do not think he goes to usf, he lives ar...</td>\n",
              "      <td>[Nah, I, do, not, think, he, goes, to, usf, ,,...</td>\n",
              "      <td>[nah, i, do, not, think, he, goes, to, usf, ,,...</td>\n",
              "      <td>[nah, i, do, not, think, he, goes, to, usf, he...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                            no_punc\n",
              "0   ham  ...  [go, until, jurong, point, crazy.., available,...\n",
              "1   ham  ...         [ok, lar, ..., joking, wif, you, oni, ...]\n",
              "2  spam  ...  [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
              "3   ham  ...  [you, dun, say, so, early, hor, ..., you, c, a...\n",
              "4   ham  ...  [nah, i, do, not, think, he, goes, to, usf, he...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNQNTiTuvrDE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "20d12827-cc7a-4fc4-f53d-03409d3db1dd"
      },
      "source": [
        "    # Spell Checking\n",
        "!pip install pyspellchecker"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspellchecker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/d1/ec4e830e9f9c1fd788e1459dd09279fdf807bc7a475579fd7192450b879c/pyspellchecker-0.5.4-py2.py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 2.9MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DTyx2yQxPUS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "6ff371d5-47ee-4044-f758-89bc63fba486"
      },
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "spell = SpellChecker()\n",
        "\n",
        "# find those words that may be misspelled\n",
        "#misspelled = spell.unknown(['something', 'is', 'hapenning', 'here'])\n",
        "misspelled_sms = spell.unknown(sms['no_punc'])\n",
        "\n",
        "for word in misspelled:\n",
        "    # Get the one `most likely` answer\n",
        "    print(spell.correction(word))\n",
        "\n",
        "    # Get a list of `likely` options\n",
        "    print(spell.candidates(word))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-f4dfc9caad5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# find those words that may be misspelled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#misspelled = spell.unknown(['something', 'is', 'hapenning', 'here'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmisspelled_sms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'no_punc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmisspelled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spellchecker/spellchecker.py\u001b[0m in \u001b[0;36munknown\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    206\u001b[0m         tmp = [\n\u001b[1;32m    207\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_case_sensitive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_if_should_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spellchecker/spellchecker.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_case_sensitive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_if_should_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         ]\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_word_frequency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spellchecker/spellchecker.py\u001b[0m in \u001b[0;36m_check_if_should_check\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# check if it is a number (int, float, etc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY3tFOI2xV8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "24526712-b13f-4529-ac93-5281ea0bbea1"
      },
      "source": [
        "# Stop words \n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXAZvaTKxdH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "1e3e0159-0dbe-4f61-9f40-3d4018ccf371"
      },
      "source": [
        "sms['stopwords_removed'] = sms['no_punc'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "sms.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>msg</th>\n",
              "      <th>length</th>\n",
              "      <th>no_contract</th>\n",
              "      <th>msg_str</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>lower</th>\n",
              "      <th>no_punc</th>\n",
              "      <th>stopwords_removed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "      <td>[Go, until, jurong, point,, crazy.., Available...</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>[Go, until, jurong, point, ,, crazy.., Availab...</td>\n",
              "      <td>[go, until, jurong, point, ,, crazy.., availab...</td>\n",
              "      <td>[go, until, jurong, point, crazy.., available,...</td>\n",
              "      <td>[go, jurong, point, crazy.., available, bugis,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "      <td>[Ok, lar..., Joking, wif, you, oni...]</td>\n",
              "      <td>Ok lar... Joking wif you oni...</td>\n",
              "      <td>[Ok, lar, ..., Joking, wif, you, oni, ...]</td>\n",
              "      <td>[ok, lar, ..., joking, wif, you, oni, ...]</td>\n",
              "      <td>[ok, lar, ..., joking, wif, you, oni, ...]</td>\n",
              "      <td>[ok, lar, ..., joking, wif, oni, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "      <td>[you, dun, say, so, early, hor..., you, c, alr...</td>\n",
              "      <td>you dun say so early hor... you c already then...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "      <td>[dun, say, early, hor, ..., c, already, say, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "      <td>[Nah, I, do not, think, he, goes, to, usf,, he...</td>\n",
              "      <td>Nah I do not think he goes to usf, he lives ar...</td>\n",
              "      <td>[Nah, I, do, not, think, he, goes, to, usf, ,,...</td>\n",
              "      <td>[nah, i, do, not, think, he, goes, to, usf, ,,...</td>\n",
              "      <td>[nah, i, do, not, think, he, goes, to, usf, he...</td>\n",
              "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                  stopwords_removed\n",
              "0   ham  ...  [go, jurong, point, crazy.., available, bugis,...\n",
              "1   ham  ...              [ok, lar, ..., joking, wif, oni, ...]\n",
              "2  spam  ...  [free, entry, 2, wkly, comp, win, fa, cup, fin...\n",
              "3   ham  ...  [dun, say, early, hor, ..., c, already, say, ...]\n",
              "4   ham  ...     [nah, think, goes, usf, lives, around, though]\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRFcKzh7xq-4",
        "colab_type": "text"
      },
      "source": [
        "## Stemming/Lemmatization \n",
        "Lemmatization :  \n",
        "1. POS \n",
        "2. POS conversion to wordnet's format \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN9PQsk1xgdk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "2f45116b-41c6-4d27-c74a-206dc477c166"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GouinrTxxn3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "92e6fe49-b843-42bb-e71c-6a691dd1e15b"
      },
      "source": [
        "sms['pos_tags'] = sms['stopwords_removed'].apply(nltk.tag.pos_tag)\n",
        "sms.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>msg</th>\n",
              "      <th>length</th>\n",
              "      <th>no_contract</th>\n",
              "      <th>msg_str</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>lower</th>\n",
              "      <th>no_punc</th>\n",
              "      <th>stopwords_removed</th>\n",
              "      <th>pos_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "      <td>[Go, until, jurong, point,, crazy.., Available...</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>[Go, until, jurong, point, ,, crazy.., Availab...</td>\n",
              "      <td>[go, until, jurong, point, ,, crazy.., availab...</td>\n",
              "      <td>[go, until, jurong, point, crazy.., available,...</td>\n",
              "      <td>[go, jurong, point, crazy.., available, bugis,...</td>\n",
              "      <td>[(go, VB), (jurong, JJ), (point, NN), (crazy.....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "      <td>[Ok, lar..., Joking, wif, you, oni...]</td>\n",
              "      <td>Ok lar... Joking wif you oni...</td>\n",
              "      <td>[Ok, lar, ..., Joking, wif, you, oni, ...]</td>\n",
              "      <td>[ok, lar, ..., joking, wif, you, oni, ...]</td>\n",
              "      <td>[ok, lar, ..., joking, wif, you, oni, ...]</td>\n",
              "      <td>[ok, lar, ..., joking, wif, oni, ...]</td>\n",
              "      <td>[(ok, JJ), (lar, NN), (..., :), (joking, VBG),...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
              "      <td>[(free, JJ), (entry, NN), (2, CD), (wkly, JJ),...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "      <td>[you, dun, say, so, early, hor..., you, c, alr...</td>\n",
              "      <td>you dun say so early hor... you c already then...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "      <td>[dun, say, early, hor, ..., c, already, say, ...]</td>\n",
              "      <td>[(dun, NNS), (say, VBP), (early, JJ), (hor, NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "      <td>[Nah, I, do not, think, he, goes, to, usf,, he...</td>\n",
              "      <td>Nah I do not think he goes to usf, he lives ar...</td>\n",
              "      <td>[Nah, I, do, not, think, he, goes, to, usf, ,,...</td>\n",
              "      <td>[nah, i, do, not, think, he, goes, to, usf, ,,...</td>\n",
              "      <td>[nah, i, do, not, think, he, goes, to, usf, he...</td>\n",
              "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
              "      <td>[(nah, RB), (think, NN), (goes, VBZ), (usf, JJ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                           pos_tags\n",
              "0   ham  ...  [(go, VB), (jurong, JJ), (point, NN), (crazy.....\n",
              "1   ham  ...  [(ok, JJ), (lar, NN), (..., :), (joking, VBG),...\n",
              "2  spam  ...  [(free, JJ), (entry, NN), (2, CD), (wkly, JJ),...\n",
              "3   ham  ...  [(dun, NNS), (say, VBP), (early, JJ), (hor, NN...\n",
              "4   ham  ...  [(nah, RB), (think, NN), (goes, VBZ), (usf, JJ...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7SXZL5GyMQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "df474c1a-27f7-4df4-b6a6-c0a4dc59ffcc"
      },
      "source": [
        "#NLTK’s word lemmatizer which needs the parts of speech tags to be converted to wordnet’s format. \n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieDGTxYOybmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We’ll write a function which make the proper conversion and then use the function within a list comprehension to apply the conversion.\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBOg2_aQykRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "4bd417ac-7a53-44bc-eafc-7b7be720a39c"
      },
      "source": [
        "sms['wordnet_pos'] = sms['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
        "sms.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>msg</th>\n",
              "      <th>length</th>\n",
              "      <th>no_contract</th>\n",
              "      <th>msg_str</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>lower</th>\n",
              "      <th>no_punc</th>\n",
              "      <th>stopwords_removed</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>wordnet_pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "      <td>[Go, until, jurong, point,, crazy.., Available...</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>[Go, until, jurong, point, ,, crazy.., Availab...</td>\n",
              "      <td>[go, until, jurong, point, ,, crazy.., availab...</td>\n",
              "      <td>[go, until, jurong, point, crazy.., available,...</td>\n",
              "      <td>[go, jurong, point, crazy.., available, bugis,...</td>\n",
              "      <td>[(go, VB), (jurong, JJ), (point, NN), (crazy.....</td>\n",
              "      <td>[(go, v), (jurong, a), (point, n), (crazy.., n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "      <td>[Ok, lar..., Joking, wif, you, oni...]</td>\n",
              "      <td>Ok lar... Joking wif you oni...</td>\n",
              "      <td>[Ok, lar, ..., Joking, wif, you, oni, ...]</td>\n",
              "      <td>[ok, lar, ..., joking, wif, you, oni, ...]</td>\n",
              "      <td>[ok, lar, ..., joking, wif, you, oni, ...]</td>\n",
              "      <td>[ok, lar, ..., joking, wif, oni, ...]</td>\n",
              "      <td>[(ok, JJ), (lar, NN), (..., :), (joking, VBG),...</td>\n",
              "      <td>[(ok, a), (lar, n), (..., n), (joking, v), (wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
              "      <td>[(free, JJ), (entry, NN), (2, CD), (wkly, JJ),...</td>\n",
              "      <td>[(free, a), (entry, n), (2, n), (wkly, a), (co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "      <td>[you, dun, say, so, early, hor..., you, c, alr...</td>\n",
              "      <td>you dun say so early hor... you c already then...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "      <td>[dun, say, early, hor, ..., c, already, say, ...]</td>\n",
              "      <td>[(dun, NNS), (say, VBP), (early, JJ), (hor, NN...</td>\n",
              "      <td>[(dun, n), (say, v), (early, a), (hor, n), (.....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "      <td>[Nah, I, do not, think, he, goes, to, usf,, he...</td>\n",
              "      <td>Nah I do not think he goes to usf, he lives ar...</td>\n",
              "      <td>[Nah, I, do, not, think, he, goes, to, usf, ,,...</td>\n",
              "      <td>[nah, i, do, not, think, he, goes, to, usf, ,,...</td>\n",
              "      <td>[nah, i, do, not, think, he, goes, to, usf, he...</td>\n",
              "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
              "      <td>[(nah, RB), (think, NN), (goes, VBZ), (usf, JJ...</td>\n",
              "      <td>[(nah, r), (think, n), (goes, v), (usf, a), (l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                        wordnet_pos\n",
              "0   ham  ...  [(go, v), (jurong, a), (point, n), (crazy.., n...\n",
              "1   ham  ...  [(ok, a), (lar, n), (..., n), (joking, v), (wi...\n",
              "2  spam  ...  [(free, a), (entry, n), (2, n), (wkly, a), (co...\n",
              "3   ham  ...  [(dun, n), (say, v), (early, a), (hor, n), (.....\n",
              "4   ham  ...  [(nah, r), (think, n), (goes, v), (usf, a), (l...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgbRSCabypc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "5ce31f2b-a644-463f-dce5-4aa9c014bca7"
      },
      "source": [
        "# Now we can apply NLTK’s word lemmatizer within our trusty list comprehension. \n",
        "# Notice, the lemmatizer function requires two parameters the word and its tag (in wordnet form).\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wnl = WordNetLemmatizer()\n",
        "sms['lemmatized'] = sms['wordnet_pos'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])\n",
        "sms.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>msg</th>\n",
              "      <th>length</th>\n",
              "      <th>no_contract</th>\n",
              "      <th>msg_str</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>lower</th>\n",
              "      <th>no_punc</th>\n",
              "      <th>stopwords_removed</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>wordnet_pos</th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "      <td>[Go, until, jurong, point,, crazy.., Available...</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>[Go, until, jurong, point, ,, crazy.., Availab...</td>\n",
              "      <td>[go, until, jurong, point, ,, crazy.., availab...</td>\n",
              "      <td>[go, until, jurong, point, crazy.., available,...</td>\n",
              "      <td>[go, jurong, point, crazy.., available, bugis,...</td>\n",
              "      <td>[(go, VB), (jurong, JJ), (point, NN), (crazy.....</td>\n",
              "      <td>[(go, v), (jurong, a), (point, n), (crazy.., n...</td>\n",
              "      <td>[go, jurong, point, crazy.., available, bugis,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "      <td>[Ok, lar..., Joking, wif, you, oni...]</td>\n",
              "      <td>Ok lar... Joking wif you oni...</td>\n",
              "      <td>[Ok, lar, ..., Joking, wif, you, oni, ...]</td>\n",
              "      <td>[ok, lar, ..., joking, wif, you, oni, ...]</td>\n",
              "      <td>[ok, lar, ..., joking, wif, you, oni, ...]</td>\n",
              "      <td>[ok, lar, ..., joking, wif, oni, ...]</td>\n",
              "      <td>[(ok, JJ), (lar, NN), (..., :), (joking, VBG),...</td>\n",
              "      <td>[(ok, a), (lar, n), (..., n), (joking, v), (wi...</td>\n",
              "      <td>[ok, lar, ..., joke, wif, oni, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
              "      <td>[(free, JJ), (entry, NN), (2, CD), (wkly, JJ),...</td>\n",
              "      <td>[(free, a), (entry, n), (2, n), (wkly, a), (co...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "      <td>[you, dun, say, so, early, hor..., you, c, alr...</td>\n",
              "      <td>you dun say so early hor... you c already then...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
              "      <td>[dun, say, early, hor, ..., c, already, say, ...]</td>\n",
              "      <td>[(dun, NNS), (say, VBP), (early, JJ), (hor, NN...</td>\n",
              "      <td>[(dun, n), (say, v), (early, a), (hor, n), (.....</td>\n",
              "      <td>[dun, say, early, hor, ..., c, already, say, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "      <td>[Nah, I, do not, think, he, goes, to, usf,, he...</td>\n",
              "      <td>Nah I do not think he goes to usf, he lives ar...</td>\n",
              "      <td>[Nah, I, do, not, think, he, goes, to, usf, ,,...</td>\n",
              "      <td>[nah, i, do, not, think, he, goes, to, usf, ,,...</td>\n",
              "      <td>[nah, i, do, not, think, he, goes, to, usf, he...</td>\n",
              "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
              "      <td>[(nah, RB), (think, NN), (goes, VBZ), (usf, JJ...</td>\n",
              "      <td>[(nah, r), (think, n), (goes, v), (usf, a), (l...</td>\n",
              "      <td>[nah, think, go, usf, life, around, though]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                         lemmatized\n",
              "0   ham  ...  [go, jurong, point, crazy.., available, bugis,...\n",
              "1   ham  ...                [ok, lar, ..., joke, wif, oni, ...]\n",
              "2  spam  ...  [free, entry, 2, wkly, comp, win, fa, cup, fin...\n",
              "3   ham  ...  [dun, say, early, hor, ..., c, already, say, ...]\n",
              "4   ham  ...        [nah, think, go, usf, life, around, though]\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkvQURhpyz0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lastly, we should save all of our pre-processing work for the next steps in the workflow. We can simnple save it as a csv file.\n",
        "sms.to_csv('sms_spam_collection.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4HrFeIc0Ing",
        "colab_type": "text"
      },
      "source": [
        "# 2. Feature engineering\n",
        "\n",
        "1. Part of Speech (POS)\n",
        "2. Shallow Parsing or Chunking\n",
        "3. Named Entity Recognition (NER)\n",
        "4. N-Grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb9xCfNI0Trm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}